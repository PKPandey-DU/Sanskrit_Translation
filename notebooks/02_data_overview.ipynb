{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjqs9Pgb9s3ySk3HG7wfGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PKPandey-DU/Sanskrit_Translation/blob/main/notebooks/02_data_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcru_U7pI9kw"
      },
      "outputs": [],
      "source": [
        "# Mount Drive & Set Project Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_dir = '/content/drive/MyDrive/sanskrit_translation_data'  # change if required\n",
        "data_dir = f'{project_dir}/data'\n",
        "\n",
        "# Load the sample data files from /data\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "corpus_path = os.path.join(data_dir, \"corpus_sample.csv\")\n",
        "input_path = os.path.join(data_dir, \"example_input.txt\")\n",
        "output_path = os.path.join(data_dir, \"example_output.txt\")\n",
        "\n",
        "df = pd.read_csv(corpus_path)\n",
        "df.head()\n",
        "\n",
        "# Display text files\n",
        "with open(input_path, 'r', encoding='utf-8') as f:\n",
        "    print(f.read())\n",
        "\n",
        "with open(output_path, 'r', encoding='utf-8') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Create a Cleaned Version of Corpus\n",
        "def basic_clean(text):\n",
        "    text = text.strip()\n",
        "    # add more rules later\n",
        "    return text\n",
        "\n",
        "df['cleaned'] = df['text'].apply(basic_clean)\n",
        "df.head()\n",
        "\n",
        "# Save cleaned corpus\n",
        "clean_path = os.path.join(data_dir, \"corpus_cleaned.csv\")\n",
        "df.to_csv(clean_path, index=False)\n",
        "clean_path\n"
      ]
    }
  ]
}