{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Use HuggingFace Seq2SeqTrainer on parallel data; skeleton only\n",
        "\n",
        "!pip install transformers datasets sacrebleu accelerate\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from src.sanskrit_translation.paths import TRANSFORMER_DIR\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-mul-en\"  # or another\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# build HF Dataset from your parallel corpus (sa_text, en_text)\n",
        "# tokenize_fn, data_collator, training_args, trainer ...\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(TRANSFORMER_DIR)\n",
        "tokenizer.save_pretrained(TRANSFORMER_DIR)\n"
      ],
      "metadata": {
        "id": "ZuRwhUnOfqg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}